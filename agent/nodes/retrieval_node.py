import uuid
from typing import List, Dict, Any

from langchain_core.documents import Document
from langchain_core.runnables import RunnableConfig

from agent.nodes import RerankNode
from agent.schemas import ExecutionPlan
from agent.state import AgentState
from retriever.MilvusHybridRetriever import MilvusHybridRetriever


class RetrievalNode:
    """æ£€ç´¢èŠ‚ç‚¹ï¼Œåˆå¹¶äº†RerankNodeï¼ŒåŒ…å«äº†ç²—ç­›ï¼ˆRetrieveï¼‰å’Œç²¾ç­›ï¼ˆRerankï¼‰"""
    def __init__(self, retriever: MilvusHybridRetriever, reranker: RerankNode):
        """
        åˆå§‹åŒ–æ£€ç´¢èŠ‚ç‚¹
        :param retriever: å·²ç»åˆå§‹åŒ–å¥½çš„ MilvusHybridRetriever å®ä¾‹
        """
        self.retriever = retriever
        self.reranker = reranker

    def __call__(self, state: AgentState, config: RunnableConfig) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ£€ç´¢é€»è¾‘
        """
        # 1. è·å–ä¸Šä¸€ä¸ªèŠ‚ç‚¹çš„åˆ†æç»“æœ
        plan: ExecutionPlan = state.get("plan")

        # å®‰å…¨æ£€æŸ¥ï¼šå¦‚æœæ²¡æœ‰åˆ†æç»“æœæˆ–æ²¡æœ‰ç”Ÿæˆæœç´¢æŸ¥è¯¢ï¼Œç›´æ¥è¿”å›ç©º
        if not plan or not plan.search_queries:
            print("âŒ No search queries found in state.")
            return {"retrieved_docs": [], "error": "No queries in plan"}

        # è·å–å½“å‰æ¬¡æ•° (é»˜è®¤ä¸º0)
        current_attempts = state.get("retrieval_attempts", 0)
        print(f"   ğŸ”„ Retrieval Attempts: {current_attempts + 1}")

        all_retrieved_docs = []

        # 2. éå†æ‰€æœ‰ Query è¿›è¡Œæ£€ç´¢
        for query in plan.search_queries:
            try:
                # è°ƒç”¨ MilvusHybridRetriever
                # æ³¨æ„ï¼šretriever.invoke æ˜¯ LangChain æ ‡å‡†æ¥å£ï¼Œåº•å±‚ä¼šè°ƒç”¨ _get_relevant_documents
                docs = self.retriever.invoke(query)
                all_retrieved_docs.extend(docs)
                print(f"   Query: '{query}' -> Found {len(docs)} docs")
            except Exception as e:
                print(f"âŒ Error retrieving for query '{query}': {e}")
                # å•ä¸ª query å¤±è´¥ä¸åº”é˜»æ–­æ•´ä¸ªæµç¨‹
                continue

        # 3. æ–‡æ¡£å»é‡ (Deduplication)
        # ä¸åŒçš„ query å¯èƒ½ä¼šå¬å›ç›¸åŒçš„æ–‡æ¡£ç‰‡æ®µï¼Œéœ€è¦åŸºäº pk å»é‡
        unique_docs = self._deduplicate(all_retrieved_docs)

        # 4. æ›´æ–°çŠ¶æ€ç”¨äº Rerank å­èŠ‚ç‚¹
        # Rerank éœ€è¦çŸ¥é“ retrieved_docsã€technical summaryã€last_message
        state_for_rerank = {
            "retrieved_docs": unique_docs,
            "analysis": state.get("analysis"),
            "message": state.get("messages")
        }

        # 3. è°ƒç”¨ Rerank é€»è¾‘ (å‡è®¾ RerankNode å·²ç»æ˜¯ä¸€ä¸ª callable)
        # è¿™é‡Œä¸ºäº†ç®€å•ï¼Œå‡è®¾æˆ‘ä»¬å¯ä»¥ç›´æ¥å¤ç”¨ reranker å®ä¾‹çš„æ–¹æ³•
        # æˆ–è€…åœ¨è¿™é‡Œç›´æ¥å®ä¾‹åŒ– RerankNode å¹¶è°ƒç”¨
        reranked_result = self.reranker(state_for_rerank, config=config)

        final_docs = reranked_result.get("retrieved_chunks", [])
        print(f"   Found {len(final_docs)} relevant docs.")

        return {
            "retrieved_docs": final_docs,
            "tool_output": None,
            "retrieval_attempts": current_attempts + 1
        }  # æ¸…ç©ºä¹‹å‰çš„å·¥å…·è¾“å‡º

    @staticmethod
    def _deduplicate(documents: List[Document]) -> List[Document]:
        """
        åŸºäºæ–‡æ¡£çš„ metadata['pk'] è¿›è¡Œå»é‡
        å¦‚æœ pk ä¸å­˜åœ¨ï¼Œåˆ™å›é€€åˆ°ä½¿ç”¨ page_content çš„å“ˆå¸Œå€¼
        """
        unique_docs = []
        seen_ids = set()

        for doc in documents:
            # ä¼˜å…ˆä½¿ç”¨æ•°æ®åº“ä¸»é”® pk
            doc_id = doc.metadata.get("pk")

            # å¦‚æœ retrieve çš„æ—¶å€™æ²¡æœ‰æ‹‰å– pkï¼Œåˆ™ä½¿ç”¨å†…å®¹çš„å“ˆå¸Œå…œåº•
            if not doc_id:
                title = doc.metadata.get("title")
                doc_id = str(uuid.uuid5(uuid.NAMESPACE_URL, title))

            if doc_id not in seen_ids:
                seen_ids.add(doc_id)
                unique_docs.append(doc)

        return unique_docs