import uuid
from typing import List, Dict, Any
from langchain_core.documents import Document
from langchain_core.runnables import RunnableConfig

from retriever.MilvusHybridRetriever import MilvusHybridRetriever
from agent.state import AgentState


class RetrievalNode:
    def __init__(self, retriever: MilvusHybridRetriever):
        """
        åˆå§‹åŒ–æ£€ç´¢èŠ‚ç‚¹
        :param retriever: å·²ç»åˆå§‹åŒ–å¥½çš„ MilvusHybridRetriever å®ä¾‹
        """
        self.retriever = retriever

    def __call__(self, state: AgentState, config: RunnableConfig) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ£€ç´¢é€»è¾‘
        """
        # 1. è·å–ä¸Šä¸€ä¸ªèŠ‚ç‚¹çš„åˆ†æç»“æœ
        analysis = state.get("analysis")

        # å®‰å…¨æ£€æŸ¥ï¼šå¦‚æœæ²¡æœ‰åˆ†æç»“æœæˆ–æ²¡æœ‰ç”Ÿæˆæœç´¢æŸ¥è¯¢ï¼Œç›´æ¥è¿”å›ç©º
        if not analysis or not analysis.search_queries:
            print("âŒ No search queries found in state.")
            return {"retrieved_docs": []}

        # è·å–å½“å‰æ¬¡æ•° (é»˜è®¤ä¸º0)
        current_attempts = state.get("retrieval_attempts", 0)
        print(f"   ğŸ”„ Retrieval Attempts: {current_attempts + 1}")

        queries = analysis.search_queries

        all_retrieved_docs = []

        # 2. éå†æ‰€æœ‰ Query è¿›è¡Œæ£€ç´¢
        for query in queries:
            try:
                # è°ƒç”¨ MilvusHybridRetriever
                # æ³¨æ„ï¼šretriever.invoke æ˜¯ LangChain æ ‡å‡†æ¥å£ï¼Œåº•å±‚ä¼šè°ƒç”¨ _get_relevant_documents
                docs = self.retriever.invoke(query)
                all_retrieved_docs.extend(docs)
                print(f"   Query: '{query}' -> Found {len(docs)} docs")
            except Exception as e:
                print(f"âŒ Error retrieving for query '{query}': {e}")
                # å•ä¸ª query å¤±è´¥ä¸åº”é˜»æ–­æ•´ä¸ªæµç¨‹
                continue

        # 3. æ–‡æ¡£å»é‡ (Deduplication)
        # ä¸åŒçš„ query å¯èƒ½ä¼šå¬å›ç›¸åŒçš„æ–‡æ¡£ç‰‡æ®µï¼Œéœ€è¦åŸºäº pk å»é‡
        unique_docs = self._deduplicate_documents(all_retrieved_docs)

        # 4. æ›´æ–°çŠ¶æ€
        # æ ¹æ® state.py çš„å®šä¹‰ï¼Œæˆ‘ä»¬è¿”å›å­—å…¸ï¼ŒLangGraph ä¼šå°†å…¶åˆå¹¶åˆ° State ä¸­
        return {
            "retrieved_docs": unique_docs,
            "tool_output": None,
            "retrieval_attempts": current_attempts + 1
        }

    def _deduplicate_documents(self, documents: List[Document]) -> List[Document]:
        """
        åŸºäºæ–‡æ¡£çš„ metadata['pk'] è¿›è¡Œå»é‡
        å¦‚æœ pk ä¸å­˜åœ¨ï¼Œåˆ™å›é€€åˆ°ä½¿ç”¨ page_content çš„å“ˆå¸Œå€¼
        """
        unique_docs = []
        seen_ids = set()

        for doc in documents:
            # ä¼˜å…ˆä½¿ç”¨æ•°æ®åº“ä¸»é”® pk
            doc_id = doc.metadata.get("pk")

            # å¦‚æœ retrieve çš„æ—¶å€™æ²¡æœ‰æ‹‰å– pkï¼Œåˆ™ä½¿ç”¨å†…å®¹çš„å“ˆå¸Œå…œåº•
            if not doc_id:
                title = doc.metadata.get("title")
                doc_id = str(uuid.uuid5(uuid.NAMESPACE_URL, title))

            if doc_id not in seen_ids:
                seen_ids.add(doc_id)
                unique_docs.append(doc)

        return unique_docs