import logging
from typing import List, Dict, Any, TypedDict, Optional

from langchain_core.runnables import RunnableConfig

from agent.nodes import RerankNode
from agent.schemas import ExecutionPlan
from agent.state import AgentState
from retriever import MilvusHybridRetriever, GraphTraverser
from utils import csr_to_milvus_format


class VectorSchema(TypedDict):
    dense: Optional[List[float]]
    sparse: Optional[Dict[int, float]]

class RetrievalNode:
    """
    æ£€ç´¢èŠ‚ç‚¹ï¼Œæ‰¹å¤„ç†å‘é‡åµŒå…¥ï¼Œåˆ†ä¸‰é˜¶æ®µæ£€ç´¢ï¼šç²—ç­›ï¼ˆRetrievalï¼‰ã€æ‰©å±•ï¼ˆExpansionï¼‰å’Œç²¾ç­›ï¼ˆRerankï¼‰
    """
    logger = logging.getLogger(__name__)

    def __init__(self, retriever: MilvusHybridRetriever, traverser: GraphTraverser, reranker: RerankNode):
        """
        åˆå§‹åŒ–æ£€ç´¢èŠ‚ç‚¹
        :param retriever: å·²åˆå§‹åŒ–çš„ MilvusHybridRetriever (æŒæœ‰ embedding models)
        :param traverser: å·²åˆå§‹åŒ–çš„ GraphTraverser (åªè´Ÿè´£æ‹“æ‰‘è®¡ç®—)
        :param reranker: å·²åˆå§‹åŒ–çš„ RerankNode
        """
        self.retriever = retriever
        self.traverser = traverser
        self.reranker = reranker

    def _batch_embed_queries(self, queries: List[str]) -> Dict[str, VectorSchema]:
        """
        Batch embed all queries using models from the retriever.
        """
        if not queries:
            return {}

        # 1. Dense Embeddings (å°è¯•ä½¿ç”¨ batch æ¥å£)
        try:
            dense_vecs = self.retriever.dense_embedding_func.embed_documents(queries)
        except AttributeError:  # å›é€€åˆ°å¾ªç¯
            dense_vecs = [self.retriever.dense_embedding_func.embed_query(q) for q in queries]

        # 2. Sparse Embeddings (é€‚é… BGE-M3)
        try:
            # å‡è®¾ sparse_embedding_func æ˜¯ BGE-M3 wrapperï¼Œå…·æœ‰ encode_queries
            sparse_result = self.retriever.sparse_embedding_func.encode_queries(queries)["sparse"]
            sparse_vecs = csr_to_milvus_format(sparse_result)

        except Exception as e:
            self.logger.error(f"Batch sparse embedding failed: {e}")
            raise e

        # 3. Construct Cache
        cache = {}
        for i, query in enumerate(queries):
            cache[query] = {"dense": dense_vecs[i], "sparse": sparse_vecs[i],}

        return cache

    def __call__(self, state: AgentState, config: RunnableConfig) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ£€ç´¢é€»è¾‘
        """
        # 1. è·å–ä¸Šä¸€ä¸ªèŠ‚ç‚¹çš„åˆ†æç»“æœï¼Œå¹¶å®‰å…¨æ£€æŸ¥
        plan: ExecutionPlan = state.get("plan")
        if not plan or not plan.search_queries:
            print("âŒ No search queries found in state.")
            return {"retrieved_docs": [], "error": "No queries in plan"}

        # è·å–å½“å‰æ¬¡æ•° (é»˜è®¤ä¸º0)
        current_attempts = state.get("retrieval_attempts", 0)
        print(f"   ğŸ”„ Retrieval Attempts: {current_attempts + 1}")

        # æ‰¹é‡ Embeddingï¼Œç”Ÿæˆä¸Šä¸‹æ–‡ç¼“å­˜
        queries = plan.search_queries
        print(f"ğŸ” Processing {len(queries)} queries...")
        embedding_cache = self._batch_embed_queries(queries)

        all_candidates = []
        seen_pks = set()

        # 2. éå†æ¯ä¸ª Query (Retrieval + Expansion)
        for query in plan.search_queries:
            vectors = embedding_cache.get(query)
            try:
                # è°ƒç”¨ MilvusHybridRetriever
                # A. Hybrid Search (è·å– Anchors)
                anchors = self.retriever.search_with_vectors(
                    dense_vec=vectors['dense'],
                    sparse_vec=vectors['sparse'],
                )
                # æ ‡è®°æ¥æº
                for doc in anchors:
                    doc.metadata['retrieval_source'] = 'anchor'
                    doc.metadata['retrieval_query'] = query

                # B. Graph Expansion (ä¼ å…¥ Dense Vector å³å¯)
                expanded_docs = self.traverser.expand(anchors, vectors['dense'])

                # C. æ”¶é›†å¹¶åˆæ­¥å»é‡
                current_batch = anchors + expanded_docs
                print(f"   Query: '{query}' -> Found {len(current_batch)} docs")
                for doc in current_batch:
                    pk = doc.metadata.get("pk")
                    # å…¨å±€å»é‡ (è·¨ Query å»é‡)
                    if pk and pk not in seen_pks:
                        seen_pks.add(pk)
                        all_candidates.append(doc)

            except Exception as e:
                print(f"âŒ Error retrieving for query '{query}': {e}")
                continue    # å•ä¸ª query å¤±è´¥ä¸åº”é˜»æ–­æ•´ä¸ªæµç¨‹

        print(f"âˆ‘ Total unique candidates after expansion: {len(all_candidates)}")

        # 3. Rerank é˜¶æ®µ
        # Rerank éœ€è¦çŸ¥é“ retrieved_docsã€technical summaryã€last_message
        state_for_rerank = {
            "retrieved_docs": all_candidates,
            "analysis": state.get("analysis"),
            "message": state.get("messages")
        }

        # è°ƒç”¨ Rerank (å‡è®¾ RerankNode å·²ç»æ˜¯ä¸€ä¸ª callable)
        # è¿™é‡Œä¸ºäº†ç®€å•ï¼Œå‡è®¾æˆ‘ä»¬å¯ä»¥ç›´æ¥å¤ç”¨ reranker å®ä¾‹çš„æ–¹æ³•
        # æˆ–è€…åœ¨è¿™é‡Œç›´æ¥å®ä¾‹åŒ– RerankNode å¹¶è°ƒç”¨
        reranked_result = self.reranker(state_for_rerank, config=config)

        final_docs = reranked_result.get("retrieved_docs", [])
        print(f"   Found {len(final_docs)} relevant docs.")

        return {
            "retrieved_docs": final_docs,
            "tool_output": None,
            "retrieval_attempts": current_attempts + 1
        }  # æ¸…ç©ºä¹‹å‰çš„å·¥å…·è¾“å‡º