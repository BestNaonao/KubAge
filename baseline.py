import asyncio
import os
from typing import TypedDict, Annotated

from dotenv import load_dotenv, find_dotenv
from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage
from langchain_core.tools import Tool
from langchain_openai.chat_models import ChatOpenAI
from langgraph.graph import StateGraph, END, add_messages
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

# ==================== ç¯å¢ƒå˜é‡åŠ è½½ ====================
load_dotenv(find_dotenv())
API_KEY = os.getenv('OPENAI_API_KEY')
BASE_URL = os.getenv('OPENAI_BASE_URL')
MODEL_NAME = os.getenv('OPENAI_MODEL_NAME')

for var in [API_KEY, BASE_URL, MODEL_NAME]:
    if var is None:
        raise ValueError(f"ç¯å¢ƒå˜é‡ç¼ºå¤±ï¼š{['API_KEY', 'BASE_URL', 'MODEL_NAME'][[API_KEY, BASE_URL, MODEL_NAME].index(var)]}")
    print(f"{var} loaded (type: {type(var)})")

os.environ["LANGCHAIN_TRACING_V2"] = "false"

# ==================== è‡ªå®šä¹‰çŠ¶æ€ç±»å‹ ====================
class AgentState(TypedDict):
    messages: Annotated[list[AnyMessage], add_messages]


# ==================== å¼‚æ­¥åŠ è½½ MCP å·¥å…· ====================
async def get_k8s_tools():
    LOCAL_MCP_PATH = "../mcp-server-kubernetes"
    ENTRY_FILE = os.path.join(LOCAL_MCP_PATH, "dist", "index.js")

    if not os.path.exists(ENTRY_FILE):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°å…¥å£æ–‡ä»¶: {ENTRY_FILE}ï¼Œè¯·ç¡®è®¤æ‚¨æ˜¯å¦æ‰§è¡Œäº† npm run build")

    server_params = StdioServerParameters(
        command="node",
        args=[ENTRY_FILE],
        env={**os.environ}
    )

    print(f"æ­£åœ¨è¿æ¥æœ¬åœ° MCP æœåŠ¡: {ENTRY_FILE} ...")

    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()
            mcp_tools = await session.list_tools()
            langchain_tools = []

            for tool in mcp_tools.tools:
                # ä¿®å¤é—­åŒ…ï¼šé€šè¿‡é»˜è®¤å‚æ•°æ•è·å½“å‰ tool.name
                async def _call_mcp_tool(tool_name=tool.name, **kwargs):
                    return await session.call_tool(tool_name, arguments=kwargs)

                langchain_tools.append(
                    Tool(
                        name=tool.name,
                        description=tool.description,
                        func=None,
                        coroutine=_call_mcp_tool
                    )
                )

            print(f"âœ… æˆåŠŸåŠ è½½ {len(langchain_tools)} ä¸ªå·¥å…·: {[t.name for t in langchain_tools]}")
            return langchain_tools


# ==================== æ„å»º Agent ====================
def build_agent(tools_list):
    # åˆå§‹åŒ– LLM
    llm = ChatOpenAI(
        model=MODEL_NAME,
        base_url=BASE_URL,
        api_key=API_KEY,
        temperature=0.6,
        max_tokens=4096,
        frequency_penalty=0,
        top_p=0.95,
        extra_body={
            "top_k": 50,
            "thinking_budget": 32768,
        }
    )

    tools_by_name = {tool.name: tool for tool in tools_list}
    llm_with_tools = llm.bind_tools(tools_list)

    # --- èŠ‚ç‚¹å‡½æ•° ---
    def llm_call(state: AgentState) -> dict:
        response = llm_with_tools.invoke(
            [SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ï¼Œæ ¹æ®ç”¨æˆ·é—®é¢˜é€‰æ‹©åˆé€‚çš„å·¥å…·è°ƒç”¨ï¼Œæˆ–è€…ä¸ç”¨è°ƒç”¨å·¥å…·")]
            + state["messages"]
        )
        return {"messages": [response]}

    def tool_node(state: AgentState) -> dict:
        result = []
        last_message = state["messages"][-1]
        for tool_call in last_message.tool_calls:
            tool = tools_by_name[tool_call["name"]]
            # è°ƒç”¨å¼‚æ­¥å·¥å…·å‡½æ•°ï¼ˆåœ¨åŒæ­¥ä¸Šä¸‹æ–‡ä¸­ï¼‰
            observation = asyncio.run(tool.coroutine(**tool_call["args"]))
            result.append(ToolMessage(content=str(observation), tool_call_id=tool_call["id"]))
        return {"messages": result}

    def should_continue(state: AgentState) -> str:
        last_message = state["messages"][-1]
        return "tools" if last_message.tool_calls else END

    # --- æ„å»ºå›¾ ---
    workflow = StateGraph(AgentState)
    workflow.add_node("llm_call", llm_call)
    workflow.add_node("tool_node", tool_node)
    workflow.set_entry_point("llm_call")
    workflow.add_conditional_edges(
        "llm_call",
        should_continue,
        {"tools": "tool_node", END: END}
    )
    workflow.add_edge("tool_node", "llm_call")

    return workflow.compile()


# ==================== ä¸»è¿è¡Œå‡½æ•° ====================
async def run():
    print("ğŸš€ å¼€å§‹åˆå§‹åŒ– MCP å·¥å…·å’Œ LLM...")

    # 1. åŠ è½½å·¥å…·
    k8s_tools = await get_k8s_tools()

    # 2. æ„å»º agent
    agent = build_agent(k8s_tools)

    print("\nâœ… åˆå§‹åŒ–å®Œæˆï¼å¼€å§‹äº¤äº’...\n")

    # 3. äº¤äº’å¾ªç¯
    while True:
        try:
            user_input = input("â“ ä»Šå¤©æƒ³é—®ç‚¹ä»€ä¹ˆå‘¢ï¼Ÿï¼ˆè¾“å…¥ 'quit' é€€å‡ºï¼‰: ").strip()
            if user_input.lower() in {"quit", "exit", "q"}:
                print("ğŸ‘‹ å†è§ï¼")
                break
            if not user_input:
                continue

            # åˆå§‹çŠ¶æ€
            initial_state: AgentState = {
                "messages": [HumanMessage(content=user_input)]
            }

            # æ‰§è¡Œ agentï¼ˆåŒæ­¥ï¼‰
            final_state = agent.invoke(initial_state)

            # æå–æœ€ç»ˆ AI å›å¤
            messages = final_state["messages"]
            # ä»åå¾€å‰æ‰¾ç¬¬ä¸€ä¸ªéå·¥å…·è°ƒç”¨çš„ AI æ¶ˆæ¯
            for msg in reversed(messages):
                if msg.type == "ai" and not getattr(msg, 'tool_calls', None):
                    print(f"\nğŸ¤– åŠ©æ‰‹: {msg.content}\n")
                    break
            else:
                # fallback: æ‰“å°æœ€åä¸€æ¡æ¶ˆæ¯
                last_msg = messages[-1]
                print(f"\nğŸ¤– åŠ©æ‰‹: {getattr(last_msg, 'content', str(last_msg))}\n")

        except KeyboardInterrupt:
            print("\nğŸ‘‹ è¢«ç”¨æˆ·ä¸­æ–­ï¼Œå†è§ï¼")
            break
        except Exception as e:
            print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}\n")
            import traceback
            traceback.print_exc()


# ==================== å…¥å£ ====================
if __name__ == "__main__":
    asyncio.run(run())