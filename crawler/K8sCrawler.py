import logging
import os
import re
from abc import ABC, abstractmethod
from typing import List, Dict, Set, Tuple
from urllib.parse import urljoin

from bs4 import BeautifulSoup

from utils.html2md_utils import convert_to_markdown, get_span_path

HEADERS: Dict[str, str] = {
    "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0",
    "Connection": "keep-alive"
}
NO_REF_URL: str = "https://kubernetes.io"
BASE_URL: str = "https://kubernetes.io/zh-cn/docs/"
START_URL: str = BASE_URL + "home/"
ELEMENT_NAME_LIST: List[str] = ['p', 'h1', 'h2', 'h3', 'h4', 'li', 'code']
EXCLUDE_HREF = ["/contribute", "/blog", "/training", "/careers", "/partners", "/community", "/test",
                "/feature-gates-removed", "/reference/issues-security"]
REMOVE_TEXT: str = "æ­¤é¡µæ˜¯å¦å¯¹ä½ æœ‰å¸®åŠ©"


class K8sCrawler(ABC):
    def __init__(self, num_workers: int, save_dir: str):
        self.num_workers = num_workers
        self.save_dir = save_dir
        self.found: Set[str] = set()
        self.errored: List[str] = []  # åªè¿½åŠ 
        self.filename_counter = {}
        self.headers: Dict[str, str] = HEADERS
        self.start_url = START_URL

        # æ—¥å¿—é…ç½®
        self.logger = logging.getLogger(type(self).__name__)
        self.logger.setLevel(logging.DEBUG)
        handler = logging.FileHandler("crawler_async.log", encoding='utf-8')
        handler.setLevel(logging.DEBUG)
        handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))
        self.logger.addHandler(handler)

        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_dir, exist_ok=True)

    def initialize(self):
        self.found.clear()
        self.errored.clear()
        self.found.add(START_URL)

    @staticmethod
    def extract_new_urls(soup, url) -> List[str]:
        """æå–é¡µé¢ä¸­çš„æ–°URLå¹¶è¿”å›åˆ—è¡¨"""
        new_urls = []
        parent_elements = soup.select("ul.ul-1")
        for parent_element in parent_elements:
            for link in parent_element.find_all('a', href=True):
                href = link.get('href')
                full_url = urljoin(BASE_URL, link['href'])
                if any(prefix in href for prefix in EXCLUDE_HREF) or not full_url.startswith(BASE_URL):
                    continue
                if '#' in full_url or full_url == url:
                    continue
                new_urls.append(full_url)
        return new_urls

    def get_unique_filename(self, base_name: str) -> str:
        """ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶åï¼Œé¿å…å†²çª"""
        # å¦‚æœæ–‡ä»¶åå·²å­˜åœ¨ï¼Œæ·»åŠ è®¡æ•°å™¨åç¼€
        if base_name in self.filename_counter:
            self.filename_counter[base_name] += 1
            return f"{base_name}_{self.filename_counter[base_name]}"
        else:
            self.filename_counter[base_name] = 1
            return base_name

    def parse_html(self, html: str, url: str) -> Tuple[List[str], str, str]:
        soup = BeautifulSoup(html, 'lxml')
        new_urls = self.extract_new_urls(soup, url)
        span_name = get_span_path(soup, url, NO_REF_URL)
        markdown_content = convert_to_markdown(soup, url)
        return new_urls, span_name, markdown_content

    def save(self, markdown_content: str, url: str, doc_name: str):
        """æå–ç½‘é¡µä¸­çš„å†…å®¹ï¼ŒåŒ…æ‹¬æ ‡é¢˜å’Œæ­£æ–‡ï¼Œæœ€åä¿å­˜"""
        if not markdown_content:
            self.logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æ­£æ–‡å†…å®¹: {url}")
            return

        save_path = os.path.join(self.save_dir, f"{doc_name}.md")
        with open(save_path, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        self.logger.info(f"å·²ä¿å­˜: {save_path} (å­—ç¬¦æ•°: {len(markdown_content)})")

    def show_progress(self, done: int, total: int, active: int):
        if total > 0:
            progress = done / total * 100
            print(
                f"\rğŸ“Š è¿›åº¦: {done}/{total} ({progress:.1f}%) | é˜Ÿåˆ—: {total - done} | "
                f"æ´»è·ƒWorker: {active} / {self.num_workers} | é”™è¯¯: {len(self.errored)}", end='', flush=True
            )

    def quit_print(self):
        print("\n" + "=" * 50)
        self.logger.info(f"çˆ¬å–å®Œæˆ! æ€»å…±è®¿é—®: {len(self.found)} é¡µé¢, é”™è¯¯: {len(self.errored)}")

        if self.errored:
            self.logger.info("----- ä»¥ä¸‹URLè·å–å¤±è´¥:")
            for url in self.errored:
                self.logger.info(f"--- {url}")

    @abstractmethod
    def run(self) -> None:
        raise NotImplementedError

    def insert_title_at_regex_position(self, file_name: str, title: str, regex_pattern: str):
        """
        åœ¨æ–‡ä»¶ä¸­åŒ¹é…æ­£åˆ™è¡¨è¾¾å¼çš„ä½ç½®æ’å…¥æ ‡é¢˜

        å‚æ•°:
        file_path (str): æ–‡ä»¶è·¯å¾„
        title (str): è¦æ’å…¥çš„æ ‡é¢˜ï¼ˆå¸¦æ ¼å¼ï¼Œå¦‚"###### CEL è¡¨è¾¾å¼è§„åˆ™"ï¼‰
        regex_pattern (str): ç”¨äºæœç´¢ä½ç½®çš„æ­£åˆ™è¡¨è¾¾å¼
        """
        try:
            # è¯»å–æ–‡ä»¶å†…å®¹
            file_path = os.path.join(self.save_dir, file_name)
            with open(file_path, 'r', encoding='utf-8') as file:
                content = file.read()

            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æœç´¢åŒ¹é…ä½ç½®
            match = re.search(regex_pattern, content, re.MULTILINE)

            if match:
                # è·å–åŒ¹é…ä½ç½®
                start_pos = match.start()

                # åœ¨åŒ¹é…ä½ç½®å‰æ’å…¥æ ‡é¢˜ï¼ˆå¸¦æ¢è¡Œç¬¦ï¼‰
                new_content = content[:start_pos] + f"\n{title}\n" + content[start_pos:]

                # å†™å›æ–‡ä»¶
                with open(file_path, 'w', encoding='utf-8') as file:
                    file.write(new_content)

                print(f"æˆåŠŸåœ¨æ–‡ä»¶ä¸­æ’å…¥æ ‡é¢˜: {title}")
                print(f"æ’å…¥ä½ç½®: ç¬¬{content[:start_pos].count('\n') + 1}è¡Œé™„è¿‘")
                return True
            else:
                print("æœªæ‰¾åˆ°åŒ¹é…çš„ä½ç½®")
                return False

        except FileNotFoundError:
            print(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_name}")
            return False
        except Exception as e:
            print(f"å¤„ç†æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False

    def replace_content_by_regex(self, file_name: str, regex_pattern: str, substitute: str):
        """
        åœ¨æ–‡ä»¶ä¸­æ›¿æ¢ç¬¦åˆæ­£åˆ™è¡¨è¾¾å¼çš„å†…å®¹

        å‚æ•°:
        file_name (str): æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰
        regex_pattern (str): ç”¨äºåŒ¹é…å†…å®¹çš„æ­£åˆ™è¡¨è¾¾å¼
        substitute (str): æ›¿æ¢åçš„å­—ç¬¦ä¸²å†…å®¹
        """
        try:
            # æ„å»ºå®Œæ•´æ–‡ä»¶è·¯å¾„
            file_path = os.path.join(self.save_dir, file_name)

            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_path, 'r', encoding='utf-8') as file:
                content = file.read()

            # æ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…å†…å®¹
            if not re.search(regex_pattern, content, re.MULTILINE):
                print(f"æœªæ‰¾åˆ°åŒ¹é…å†…å®¹: {regex_pattern}")
                return False

            # æ‰§è¡Œæ›¿æ¢ï¼ˆæ›¿æ¢æ‰€æœ‰åŒ¹é…é¡¹ï¼‰
            new_content, count = re.subn(regex_pattern, substitute, content, flags=re.MULTILINE)

            # å†™å›æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as file:
                file.write(new_content)

            print(f"æˆåŠŸæ›¿æ¢ {count} å¤„å†…å®¹, åŸå§‹æ¨¡å¼: {regex_pattern}, æ›¿æ¢ä¸º: {substitute}")
            return True

        except FileNotFoundError:
            print(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_name}")
            return False
        except Exception as e:
            print(f"å¤„ç†æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False

    def move_content_by_regex(
            self,
            file_name: str,
            source_pattern: str,
            target_pattern: str,
            insert_after_group: int = 0
    ) -> bool:
        """
        å°†æ–‡ä»¶ä¸­åŒ¹é… source_pattern çš„å†…å®¹ç§»åŠ¨åˆ° target_pattern æŒ‡å®šä½ç½®

        å‚æ•°:
        file_name (str): æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰
        source_pattern (str): æºå†…å®¹æ­£åˆ™è¡¨è¾¾å¼ï¼ˆè¦ç§»åŠ¨çš„å†…å®¹ï¼‰
        target_pattern (str): ç›®æ ‡ä½ç½®æ­£åˆ™è¡¨è¾¾å¼ï¼ˆéœ€åŒ…å«åˆ†ç»„ä»¥ç²¾ç¡®å®šä½æ’å…¥ç‚¹ï¼‰
        insert_after_group (int):
            - -1: åœ¨æ•´ä¸ªç›®æ ‡åŒ¹é…å¼€å§‹å‰æ’å…¥
            - 0: åœ¨æ•´ä¸ªç›®æ ‡åŒ¹é…ç»“æŸåæ’å…¥
            - n>0: åœ¨ç¬¬nä¸ªæ•è·åˆ†ç»„ç»“æŸåæ’å…¥ï¼ˆæ¨èç”¨äºç²¾ç¡®å®šä½ï¼‰

        è¿”å›:
        bool: æ“ä½œæ˜¯å¦æˆåŠŸ
        """
        try:
            file_path = os.path.join(self.save_dir, file_name)

            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_path, 'r', encoding='utf-8') as file:
                content = file.read()

            # æ­¥éª¤1: æŸ¥æ‰¾å¹¶æå–æºå†…å®¹ï¼ˆåªå¤„ç†ç¬¬ä¸€ä¸ªåŒ¹é…ï¼‰
            source_match = re.search(source_pattern, content, flags=re.MULTILINE | re.DOTALL)
            if not source_match:
                print(f"âŒ æœªæ‰¾åˆ°æºå†…å®¹åŒ¹é…: {source_pattern}")
                return False

            source_text = source_match.group()
            source_start, source_end = source_match.span()

            # æ­¥éª¤2: æŸ¥æ‰¾ç›®æ ‡ä½ç½®ï¼ˆåœ¨åŸå§‹å†…å®¹ä¸­å®šä½ï¼Œé¿å…åˆ é™¤åä½ç½®åç§»ï¼‰
            target_match = re.search(target_pattern, content, flags=re.MULTILINE | re.DOTALL)
            if not target_match:
                print(f"âŒ æœªæ‰¾åˆ°ç›®æ ‡ä½ç½®åŒ¹é…: {target_pattern}")
                return False

            # æ­¥éª¤3: è®¡ç®—æ’å…¥ä½ç½®ï¼ˆè€ƒè™‘æºå†…å®¹åˆ é™¤å¯¹ç›®æ ‡ä½ç½®çš„å½±å“ï¼‰
            if insert_after_group == -1:
                insert_pos = target_match.start()
            elif insert_after_group == 0:
                insert_pos = target_match.end()
            else:
                # éªŒè¯åˆ†ç»„ç´¢å¼•æœ‰æ•ˆæ€§
                if insert_after_group > len(target_match.groups()):
                    print(f"âŒ ç›®æ ‡åŒ¹é…ä»…åŒ…å« {len(target_match.groups())} ä¸ªåˆ†ç»„ï¼Œæ— æ³•ä½¿ç”¨åˆ†ç»„ {insert_after_group}")
                    return False
                insert_pos = target_match.end(insert_after_group)

            # è°ƒæ•´æ’å…¥ä½ç½®ï¼šå¦‚æœæºå†…å®¹åœ¨ç›®æ ‡ä½ç½®ä¹‹å‰ï¼Œåˆ é™¤åç›®æ ‡ä½ç½®ä¼šå‰ç§»
            if source_end <= insert_pos:
                insert_pos -= (source_end - source_start)

            # æ­¥éª¤4: æ„å»ºæ–°å†…å®¹ï¼ˆå…ˆåˆ é™¤æºå†…å®¹ï¼Œå†åœ¨ç›®æ ‡ä½ç½®æ’å…¥ï¼‰
            # å…ˆåˆ é™¤æºå†…å®¹ï¼ˆä¿ç•™åŸå§‹å†…å®¹ç”¨äºä½ç½®è®¡ç®—ï¼‰
            content_without_source = content[:source_start] + content[source_end:]

            # åœ¨è°ƒæ•´åçš„ä½ç½®æ’å…¥
            new_content = (
                    content_without_source[:insert_pos] +
                    f" {source_text}" +
                    content_without_source[insert_pos:]
            )

            # æ­¥éª¤5: å†™å›æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as file:
                file.write(new_content)

            # è¾“å‡ºè°ƒè¯•ä¿¡æ¯
            source_preview = source_text[:60].replace('\n', '\\n') + ("..." if len(source_text) > 60 else "")
            print(f"âœ… æˆåŠŸç§»åŠ¨å†…å®¹: '{source_preview}'")
            print(f"   æºä½ç½®: ç¬¬{content[:source_start].count(chr(10)) + 1}è¡Œ")
            print(f"   ç›®æ ‡ä½ç½®: ç¬¬{content[:insert_pos].count(chr(10)) + 1}è¡Œ (åˆ†ç»„{insert_after_group}å)")
            return True

        except FileNotFoundError:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_name}")
            return False
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {type(e).__name__}: {e}")
            return False