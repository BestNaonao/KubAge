from typing import List
from langgraph.constants import START, END
from langgraph.graph import StateGraph

# å‡è®¾è¿™äº›æ˜¯ä½ é¡¹ç›®ä¸­çš„å®é™…æ¨¡å—
from agent.nodes.analysis_node import AnalysisNode
from agent.state import AgentState
from utils.model_factory import get_chat_model
from test_dataset.analysis_cases import ALL_SCENARIOS, AnalysisTestScenario


def analysis_workflow_test(scenarios: List[AnalysisTestScenario]):
    print("ğŸš€ Starting Analysis Node Workflow Test Batch...")

    # ==========================================
    # 1. æ„å»ºå›¾ (Build the Graph - åªéœ€æ„å»ºä¸€æ¬¡)
    # ==========================================

    # åˆå§‹åŒ–å¤§æ¨¡å‹
    llm = get_chat_model(
        temperature=0.1,  # æµ‹è¯•æ—¶å»ºè®®é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„ç»“æœ
        extra_body={
            "top_k": 20,
            "thinking_budget": 8192,
        }
    )

    # åˆå§‹åŒ– StateGraph
    workflow = StateGraph(AgentState)
    analysis_node = AnalysisNode(llm)

    workflow.add_node("analyze_problem", analysis_node)
    workflow.add_edge(START, "analyze_problem")
    workflow.add_edge("analyze_problem", END)

    app = workflow.compile()

    # ==========================================
    # 2. å¾ªç¯è¿è¡Œæµ‹è¯•ç”¨ä¾‹
    # ==========================================

    success_count = 0
    total_count = len(scenarios)

    for i, case in enumerate(scenarios, 1):
        print(f"\n{'=' * 20} Test Case {i}/{total_count}: {case.name} {'=' * 20}")

        try:
            # è¿è¡Œå·¥ä½œæµ
            print(f"â³ Invoking Workflow for: {case.name}...")
            final_state = app.invoke(case.user_inputs)
            analysis_result = final_state.get("analysis")

            if not analysis_result:
                print(f"âŒ Failed: Analysis result is empty.")
                continue

            print("\nâœ… Workflow Execution Succeeded!")
            print("=" * 60)

            # 1. éªŒè¯æ€ç»´é“¾ (Reasoning)å’ŒæŠ€æœ¯æ‘˜è¦
            print(f"ğŸ§  [Reasoning]:\n{analysis_result.reasoning}")
            print(f"ğŸ”§ [Technical Summary]:\n{analysis_result.technical_summary}\n")

            # 2. éªŒè¯æ„å›¾å’Œå®ä½“
            print(f"ğŸ¯ [Target Operation]: {analysis_result.target_operation}")
            print(f"ğŸ“¦ [Entities]: {[f'{e.type}:{e.name}' for e in analysis_result.entities]}")

            # 3. éªŒè¯é£é™©ç­‰çº§
            print(f"âš ï¸ [Risk Level]: {analysis_result.risk_level}")

            # 4. éªŒè¯ç”Ÿæˆçš„æ£€ç´¢è¯ (Queries)
            print(f"ğŸ” [Search Queries]:")
            for q in analysis_result.search_queries:
                print(f"  - {q}")

            # 5. éªŒè¯è¿½é—®é—®é¢˜
            print(f"â“ [Clarification Question]: {analysis_result.clarification_question}")

            # æ‰§è¡Œè‡ªå®šä¹‰æ–­è¨€éªŒè¯
            print("ğŸ” Verifying results...")
            case.verify_func(analysis_result)

            print(f"âœ… Passed!")
            success_count += 1

        except AssertionError as e:
            print(f"âŒ Assertion Failed: {str(e)}")
        except Exception as e:
            print(f"âŒ Runtime Error: {str(e)}")

    print("\n" + "=" * 60)
    print(f"ğŸ“Š Test Summary: {success_count}/{total_count} passed.")
    print("=" * 60)


if __name__ == "__main__":
    analysis_workflow_test(ALL_SCENARIOS)