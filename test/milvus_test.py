import os
import random

from dotenv import load_dotenv, find_dotenv
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_milvus import Milvus
from pymilvus import Collection, connections

from utils.rag_utils import get_full_node_content

# ==================== ç¯å¢ƒå˜é‡åŠ è½½ ====================
load_dotenv(find_dotenv())
MILVUS_HOST = os.getenv('MILVUS_HOST')
MILVUS_PORT = os.getenv('MILVUS_PORT')
MILVUS_USER = os.getenv('MILVUS_USER')
MILVUS_PASSWORD = os.getenv('MILVUS_ROOT_PASSWORD')

def milvus_store(embedding_model, collection_name, index_params=None, search_params=None) -> Milvus:
    return Milvus(
        embedding_function=embedding_model,
        connection_args={
            "host": MILVUS_HOST,
            "port": MILVUS_PORT,
            "user": MILVUS_USER,
            "password": MILVUS_PASSWORD,
        },
        collection_name=collection_name,
        index_params=index_params,
        search_params=search_params,
    )

def basic_test(embedding_model, collection_name):
    # è¿æ¥åˆ° Milvus
    vector_store = milvus_store(
        embedding_model,
        collection_name,
        # æ³¨æ„ï¼šindex_params åœ¨ add_texts é¦–æ¬¡è°ƒç”¨æ—¶æ‰ä¼šç”Ÿæ•ˆï¼ˆå¦‚æœé›†åˆä¸å­˜åœ¨ï¼‰
        index_params={
            "index_type": "HNSW",
            "metric_type": "COSINE",
            "params": {"M": 16, "efConstruction": 200}
        },
        # æœç´¢å‚æ•°
        search_params={
            "metric_type": "COSINE",
            "params": {"ef": 64}  # æœç´¢æ—¶çš„ ef å€¼
        }
    )

    # æ·»åŠ æ–‡æœ¬ï¼ˆä¼šè§¦å‘é›†åˆåˆ›å»º + ç´¢å¼•æ„å»ºï¼‰
    texts = ["æˆ‘çš„å§“åå«BestNaonao", "æˆ‘æœ€å–œæ¬¢æ‘¸é±¼äº†ï¼"]
    vector_store.add_texts(texts)

    # æŸ¥è¯¢
    results = vector_store.similarity_search("åå­—", k=2)
    print(results)
    results2 = vector_store.similarity_search_with_score("å§“å", k=2)

    print("\n=== æŸ¥è¯¢ç»“æœï¼ˆå¸¦åˆ†æ•°ï¼‰ ===")
    for i, (doc, score) in enumerate(results2, 1):
        print(f"ç»“æœ {i}:")
        print(f"  å†…å®¹: {doc.page_content}")
        print(f"  ç›¸ä¼¼åº¦: {score:.4f}")      # æ³¨æ„ï¼šMilvus COSINE ä¸‹ score æ˜¯è·ç¦»ï¼ˆè¶Šå°è¶Šç›¸ä¼¼ï¼‰ï¼Ÿ
        print(f"  å…ƒæ•°æ®: {doc.metadata}")

    results3 = vector_store.similarity_search_with_score("çˆ±å¥½", k=2)

    print("=== æŸ¥è¯¢ç»“æœï¼ˆå¸¦åˆ†æ•°ï¼‰ ===")
    for i, (doc, score) in enumerate(results3, 1):
        print(f"ç»“æœ {i}:")
        print(f"  å†…å®¹: {doc.page_content}")
        print(f"  ç›¸ä¼¼åº¦: {score:.4f}")      # æ³¨æ„ï¼šMilvus COSINE ä¸‹ score æ˜¯è·ç¦»ï¼ˆè¶Šå°è¶Šç›¸ä¼¼ï¼‰ï¼Ÿ
        print(f"  å…ƒæ•°æ®: {doc.metadata}")

    # æ¸…ç©ºè¿™ä¸ªè¡¨çš„æ•°æ®
    print("=== æ¸…ç©ºæ•°æ®åº“ ===")
    connections.connect(
        host=MILVUS_HOST,
        port=MILVUS_PORT,
        user=MILVUS_USER,
        password=MILVUS_PASSWORD,
        # å¯é€‰ï¼šæŒ‡å®š aliasï¼Œä½†é»˜è®¤ "default" å³å¯
    )
    collection = Collection(collection_name)
    collection.load()
    result = collection.query(
        expr="pk >= 0",  # æŸ¥è¯¢æ‰€æœ‰è®°å½•
        output_fields=["pk"]  # pk æ˜¯ä¸»é”®å­—æ®µå
    )
    if result:
        # æå–æ‰€æœ‰ ID
        ids_to_delete = [item["pk"] for item in result]
        # æ‰¹é‡åˆ é™¤
        collection.delete(f"pk in {ids_to_delete}")
        print(f"âœ… å·²åˆ é™¤ {len(ids_to_delete)} æ¡è®°å½•")
    else:
        print("âš ï¸ Collection ä¸ºç©º")
    # åˆ·æ–°
    collection.flush()

def kb_test(milvus: Milvus):

    def condition_query(expr: str):
        docs = milvus.search_by_metadata(
            expr=expr,
            limit=500
        )
        print(f"å…± {len(docs)} æ¡")
        for doc in docs[:10]:
            print(doc.metadata['title'])
        return docs

    print("========= â€œæ¥ä¸‹æ¥â€å’Œâ€œå¦è¯·å‚è§â€å¯¼èˆªç« èŠ‚æµ‹è¯• =========")
    condition_query("text like '%# æ¥ä¸‹æ¥%'")
    condition_query("text like '%# å¦è¯·å‚è§%'")

    print("========= APIå—æµ‹è¯• =========")

    condition_1 = "(text like '%# HTTP%')"
    condition_2 = "(text like '%# å‚æ•°%' or text like '%# Parameter%')"
    condition_3 = "(text like '%# å“åº”%' or text like '%# Response%')"

    condition_4 = "(text like '%**HTTP%')"
    condition_5 = "(text like '%**å‚æ•°**%' or text like '%**Parameter%')"
    condition_6 = "(text like '%**å“åº”**%' or text like '%**Response%')"

    condition_7 = "(title like 'æ–‡æ¡£_å‚è€ƒ_Kubernetes API%')"

    def satisfy_2_at_least(c1, c2, c3):
        return f"(({c1} and {c2}) or ({c2} and {c3}) or ({c3} and {c1}))"

    satisfy_1_2_3_al2 = satisfy_2_at_least(condition_1, condition_2, condition_3)
    satisfy_4_5_6_al2 = satisfy_2_at_least(condition_4, condition_5, condition_6)

    def satisfy_only_one(c1, c2, c3):
        return f"(({c1} and !{c2} and !{c3}) or (!{c1} and {c2} and !{c3}) or (!{c1} and !{c2} and {c3}))"

    print("---------è‡³å°‘æ»¡è¶³æ¡ä»¶1ã€2ã€3ä¸­çš„ä¸¤ä¸ª")
    condition_query(f"{satisfy_1_2_3_al2}")
    print("---------åªæ»¡è¶³æ¡ä»¶1ã€2ã€3ä¸­çš„ä¸€ä¸ªï¼Œå¹¶ä¸”æ»¡è¶³æ¡ä»¶7")
    condition_query(f"{satisfy_only_one(condition_1, condition_2, condition_3)} and {condition_7}")
    print("---------è‡³å°‘æ»¡è¶³æ¡ä»¶4ã€5ã€6ä¸­çš„ä¸¤ä¸ª")
    condition_query(f"{satisfy_4_5_6_al2}")
    print("---------è‡³å°‘æ»¡è¶³æ¡ä»¶4ã€5ã€6ä¸­çš„ä¸¤ä¸ªï¼Œå¹¶ä¸”ä¸æ»¡è¶³æ¡ä»¶7")
    condition_query(f"{satisfy_4_5_6_al2} and !{condition_7}")
    print("---------åªæ»¡è¶³æ¡ä»¶4ã€5ã€6ä¸­çš„ä¸€ä¸ªï¼Œå¹¶ä¸”æ»¡è¶³æ¡ä»¶7")
    condition_query(f"{satisfy_only_one(condition_4, condition_5, condition_6)} and {condition_7}")
    print("---------åªæ»¡è¶³æ¡ä»¶4ã€5ã€6ä¸­çš„ä¸€ä¸ªï¼Œå¹¶ä¸”ä¸æ»¡è¶³æ¡ä»¶7")
    condition_query(f"{satisfy_only_one(condition_4, condition_5, condition_6)} and !{condition_7}")

def title_test(milvus: Milvus):
    print("========= æ ‡é¢˜å­—æ®µæµ‹è¯• =========")
    root_docs = milvus.search_by_metadata(
        expr="node_type == 'root'",
        limit = 1000
    )
    invalid_root_titles = []
    for doc in root_docs:
        title_from_source = doc.metadata['source'].split('/')[-1].split('.md')[0]
        if title_from_source != doc.metadata['title']:
            invalid_root_titles.append(title_from_source)
    print(f"æ ‡é¢˜éæ³•çš„æ ¹èŠ‚ç‚¹æ ‡é¢˜ å…±æœ‰ {len(invalid_root_titles)} ä¸ª")
    for invalid_title in invalid_root_titles:
        print(invalid_title)

def nav_test(milvus: Milvus):
    print("========= å¯¼èˆªç« èŠ‚æµ‹è¯• =========")
    invalid_nav_docs = milvus.search_by_metadata(
        expr="node_type != 'root' and (nav_next_step != '' or nav_see_also != '')",
        limit = 1000
    )
    print(f"æ˜¯å¦åŒ…å«éæ ¹èŠ‚ç‚¹çš„å¯¼èˆªå†…å®¹: {len(invalid_nav_docs) != 0}")

def rag_utils_test(milvus: Milvus):
    print("========= RAGå·¥å…·æµ‹è¯• =========")
    print(get_full_node_content(milvus, "9a0c26a5-decf-5184-b5fc-9a2e7fce0cd6"))

def hlink_cleanliness_test(milvus: Milvus):
    print("========= è¶…é“¾æ¥æ®‹ç•™æµ‹è¯• =========")
    # æ£€æµ‹å­—æ®µ
    fields_to_check = ["text", "title", "nav_next_step", "nav_see_also"]
    # æ£€æµ‹æ¨¡å¼
    patterns = ["HLINK", "ANCHOR"]

    total_dirty_docs = 0

    # ä¹Ÿå¯ä»¥æ£€æŸ¥ related_links å­—æ®µæ˜¯å¦è§£ææ­£ç¡®ï¼ˆéå­—ç¬¦ä¸²ï¼‰

    for field in fields_to_check:
        for pattern in patterns:
            # æ„é€ æ¨¡ç³ŠåŒ¹é…è¡¨è¾¾å¼ (æ³¨æ„: Milvus çš„ like åŒ¹é…å¤§å°å†™æ•æ„Ÿ)
            expr = f'{field} like "%{pattern}%"'

            try:
                # ä½¿ç”¨åº•å±‚ pymilvus collection è¿›è¡ŒæŸ¥è¯¢
                res = milvus.search_by_metadata(
                    expr=expr,
                    fields=["pk", "title"],
                    limit=5  # ä»…å–æ ·å±•ç¤º
                )

                if res:
                    print(f"âš ï¸  [å¤±è´¥] å­—æ®µ '{field}' ä¸­å‘ç°æ®‹ç•™ '{pattern}' (ç¤ºä¾‹):")
                    for doc in res:
                        print(f"    - PK: {doc.id} | Title: {doc.metadata.get('title', 'Unknown')}")
                    total_dirty_docs += len(res)
            except Exception as e:
                # æŸäº›å­—æ®µå¯èƒ½å› ä¸ºé•¿åº¦é—®é¢˜æ— æ³•æ‰§è¡Œ like æŸ¥è¯¢ï¼Œè§†æƒ…å†µå¿½ç•¥
                print(f"    [è·³è¿‡] å­—æ®µ '{field}' æŸ¥è¯¢å‡ºé”™: {e}")

    if total_dirty_docs == 0:
        print("âœ… å†…å®¹æµ‹è¯•é€šè¿‡ï¼šæœªå‘ç°æ®‹ç•™çš„ HLINK æˆ– ANCHOR æ ‡è®°ã€‚")
    else:
        print(f"âŒ å†…å®¹æµ‹è¯•å¤±è´¥ï¼šå‘ç°æ½œåœ¨æ®‹ç•™æ ‡è®°ã€‚")

def graph_traversal_test(milvus: Milvus):
    print("========= å›¾è°±è·³è½¬æµ‹è¯• (Random Walk) =========")

    # 1. è·å–ä¸€æ‰¹å€™é€‰æ–‡æ¡£ (related_links ä¸ä¸ºç©º)
    # ç”±äº Milvus å¯¹ JSON å­—æ®µçš„ç©ºå€¼æŸ¥è¯¢æ”¯æŒæœ‰é™ï¼Œæˆ‘ä»¬å…ˆæ‹‰å–ä¸€æ‰¹éæ ¹èŠ‚ç‚¹æ–‡æ¡£è¿›è¡Œç­›é€‰
    try:
        candidates_res = milvus.search_by_metadata(
            expr='pk != ""',  # è·å–æ‰€æœ‰æ–‡æ¡£ï¼ˆå—é™äº limitï¼‰
            fields=["pk", "title", "related_links"],
            limit=500
        )
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢æ–‡æ¡£å¤±è´¥: {e}")
        return

    # 2. åœ¨å†…å­˜ä¸­ç­›é€‰å‡º related_links æœ‰å†…å®¹çš„æ–‡æ¡£
    valid_candidates = [
        doc for doc in candidates_res
        if doc.metadata.get("related_links") and len(doc.metadata.get("related_links")) > 0
    ]

    if len(valid_candidates) < 3:
        print(f"âš ï¸ æœ‰æ•ˆé“¾æ¥æ–‡æ¡£ä¸è¶³ 3 ä¸ª (å½“å‰: {len(valid_candidates)})ï¼Œæ— æ³•æ‰§è¡Œæµ‹è¯•ã€‚")
        return

    # 3. éšæœºé€‰æ‹© 3 ä¸ªèµ·ç‚¹
    start_docs = random.sample(valid_candidates, 3)

    for i, start_doc in enumerate(start_docs, 1):
        print(f"\nğŸ”— [è·¯å¾„ {i}]")
        current_doc = start_doc
        print(f"   ğŸš© èµ·ç‚¹: {current_doc.metadata.get('title')}")

        steps = 0
        max_steps = 5

        while steps < max_steps:
            # è·å–å½“å‰æ–‡æ¡£çš„æ‰€æœ‰é“¾æ¥
            links = current_doc.metadata.get("related_links", [])

            # ç­›é€‰å‡ºå†…éƒ¨é“¾æ¥ (type == 'internal' ä¸” pk å­˜åœ¨)
            internal_links = [
                l for l in links
                if l.get("type") == "internal" and l.get("pk")
            ]

            if not internal_links:
                print("      ğŸ›‘ åœæ­¢: å½“å‰æ–‡æ¡£æ— å†…éƒ¨é“¾æ¥")
                break

            # éšæœºé€‰æ‹©ä¸€ä¸ªé“¾æ¥è¿›è¡Œè·³è·ƒ
            chosen_link = random.choice(internal_links)
            target_pk = chosen_link['pk']
            anchor_text = chosen_link.get('text', 'unknown')

            # æŸ¥è¯¢ç›®æ ‡æ–‡æ¡£
            next_docs = milvus.search_by_metadata(
                expr=f'pk == "{target_pk}"',
                fields=["pk", "title", "related_links"]
            )

            if not next_docs:
                print(f"      âš ï¸ é”™è¯¯: é“¾æ¥æŒ‡å‘çš„ PK {target_pk} ä¸å­˜åœ¨ (æ­»é“¾)")
                break

            next_doc = next_docs[0]
            print(f"      â¬‡ï¸  (ç‚¹å‡»: '{anchor_text}')")
            print(f"   ğŸ“ è·³è·ƒè‡³: {next_doc.metadata.get('title')}")

            current_doc = next_doc
            steps += 1

        if steps == max_steps:
            print("      ğŸ è¾¾åˆ°æœ€å¤§è·³è·ƒæ¬¡æ•°")

def main():
    embedding_path = "../models/Qwen/Qwen3-Embedding-0.6B"   # ç›¸å¯¹è·¯å¾„ï¼šä»å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•å‡ºå‘
    embedding_model = HuggingFaceEmbeddings(
        model_name=embedding_path,
        model_kwargs={
            "device": "cuda",  # å¦‚æœæ—  GPUï¼Œæ”¹ä¸º "cpu"
            "trust_remote_code": True,  # Qwen å¿…é¡»å¼€å¯
        },
        encode_kwargs={
            "normalize_embeddings": True  # Qwen æ¨èå¼€å¯ï¼Œç”¨äº COSINE ç›¸ä¼¼åº¦
        }
    )
    # basic_test(embedding_model, "my_collection")
    kb_store = milvus_store(embedding_model, "knowledge_base_v3")
    kb_test(kb_store)
    title_test(kb_store)
    nav_test(kb_store)
    rag_utils_test(kb_store)

    # æ‰§è¡Œæ–°æµ‹è¯•
    hlink_cleanliness_test(kb_store)
    graph_traversal_test(kb_store)


if __name__ == '__main__':
    main()